I develop 3d visualizations in vr for my internship. When I first started, one of the first things I asked about was automated testing. We don't use an automated testing framework, so for my curiosity report, I wanted to look more into what automated testing frameworks are out there for the work that I do. For background, I use the Unity game engine (which uses C#), and an additional VR framework called Mixed Reality Toolkit (MRTK) developed by Microsoft that enables extended reality (XR) interactions. 

The first thing I came across was the Unity Testing Framework. It's an additional package that can be added to Unity projects. According to Unity's documentation, it extends NUnit which is a testing framework for .NET platforms. Unity Testing Framework can be used for standalone testing as well as testing for mobile platforms (iOS and Android). It can test in both edit and play mode and is built right into Unity's editor and according to Unity works like test runners in Visual Studio or other IDEs. When looking at an example test, Unity's testing framework looks very similar to Playwright in that it's testing UI. I don't think that there is a way to record user input like Playwright does, so events like Press(mouse.leftButton) need to be scripted by hand. It also tests keyboard actions, like for moving a character around. When I found Unity's blog, there was a post from 2023 talking about Unity DevOps, a paid service that can run automatic build pipelines and include automated testing. From my experience, our builds/deployments are for demos, so I don't think we'll be needing to use the a DevOps build pipeline in the cloud for our needs, but it's cool to know that it's out there.   

I also wanted to research automated testing for MRTK. What I usually do to test is I'll just enter game mode and check manually to make sure that the interactions look alright and are behaving as intended. This can be very tedious. I found that you can simulate input from a script by instantiating needed elements like some UI and some virtual hands, moving the hands to interact with the UI, and checking to make sure the interactions are correct. These tests would also run in Unity's test runner from my research. Microsoft does have an example script containing some tests for MRTK 2, but that version is deprecated and Microsoft doesn't mention automated testing for the current MRTK 3 and rather recommends testing by simulating input manually in Unity's editor or by streaming to a headset. It might be faster to just test the XR environment manually, as well as to make sure that interactions are what's intended. But it's good to know that those testing materials are there and could be useful for game developers that make XR games.  